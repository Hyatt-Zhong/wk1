    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = torch.nn.Sequential(
            torch.nn.Conv2d(1, 10, kernel_size=5),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2),
        )
        self.conv2 = torch.nn.Sequential(
            torch.nn.Conv2d(10, 20, kernel_size=5),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(kernel_size=2),
        )
        self.fc = torch.nn.Sequential(
            torch.nn.Linear(320, 50),
            torch.nn.Linear(50, 10),
        )

    def forward(self, x):
        batch_size = x.size(0)
        x = self.conv1(x)  # 一层卷积层,一层池化层,一层激活层(图是先卷积后激活再池化，差别不大)
        x = self.conv2(x)  # 再来一次
        x = x.view(batch_size, -1)  # flatten 变成全连接网络需要的输入 (batch, 20,4,4) ==> (batch,320), -1 此处自动算出的是320
        x = self.fc(x)
        return x  # 最后输出的是维度为10的，也就是（对应数学符号的0~9）

LeNet-5：由Yann LeCun等人于1998年提出的卷积神经网络，是第一个成功应用于手写数字识别任务的深度学习模型。

AlexNet：由Alex Krizhevsky等人于2012年提出的卷积神经网络，是第一个在ImageNet图像分类挑战赛中取得显著优势的模型，引发了深度学习的热潮。

VGGNet：由Karen Simonyan和Andrew Zisserman于2014年提出的卷积神经网络，通过增加网络的深度和参数量，取得了更好的性能，在ImageNet挑战赛中取得了优异的成绩。

GoogLeNet：由Christian Szegedy等人于2014年提出的卷积神经网络，采用了Inception模块的结构，大幅减少了参数量，提高了网络的效率和性能。

ResNet：由Kaiming He等人于2015年提出的残差神经网络，通过引入残差连接解决了深层网络训练时的梯度消失和梯度爆炸问题，使得网络可以更深更容易训练。

LSTM：由Sepp Hochreiter和Jürgen Schmidhuber于1997年提出的长短期记忆网络，通过引入门控机制解决了传统循环神经网络中的梯度消失问题，成为处理序列数据的重要模型。

GAN：由Ian Goodfellow等人于2014年提出的生成对抗网络，通过博弈的方式训练生成器和判别器，可以生成逼真的样本，被广泛应用于图像生成和图像编辑等领域。


K-means聚类算法：将数据集划分为K个簇，每个簇的中心点代表簇的特征。该算法通过迭代优化簇的中心点位置，使得簇内样本的距离最小化。

层次聚类算法：通过计算样本之间的相似度或距离，将样本逐步合并为更大的簇，直到所有样本都合并为一个簇或满足某个停止准则。

DBSCAN聚类算法：基于密度的聚类算法，通过定义样本点的邻域半径和最小样本数，将高密度区域视为簇，并将低密度区域视为噪声。

GMM聚类算法：高斯混合模型聚类算法，假设数据集由多个高斯分布组成，通过最大似然估计确定每个高斯分布的参数，从而划分簇。

谱聚类算法：将样本集表示为一个图，通过计算图的拉普拉斯矩阵的特征向量，将样本划分为不同的簇。

深度聚类算法：结合深度学习和聚类算法，通过自编码器等深度神经网络模型，学习数据的低维表示，并利用聚类算法对低维表示进行聚类。

自组织映射（Self-Organizing Map, SOM）：也称为Kohonen神经网络，通过在输入空间中构建一个二维的网格，将样本映射到网格上的神经元，实现聚类的目标。

生成对抗网络（Generative Adversarial Networks, GAN）：GAN主要用于生成新的样本，但也可以通过对生成器中间层的特征进行聚类，实现聚类的目的。

基于变分自编码器（Variational Autoencoder, VAE）的聚类：VAE是一种生成模型，通过学习数据的潜在变量分布，可以将样本映射到低维空间，并进行聚类。

基于流形学习的聚类：流形学习算法（如t-SNE、UMAP等）可以将高维数据映射到低维空间，通过在低维空间进行聚类，实现对高维数据的聚类。

这些算法在深度学习中都有一定的应用，并在不同的场景中展现出各自的优势。根据具体的问题和数据特点，选择合适的聚类算法进行应用。

怎么做到平移不变性、尺度不变性、旋转不变性

要实现平移不变性、尺度不变性和旋转不变性，可以使用以下方法：

平移不变性：在图像处理中，可以通过在图像上进行滑动窗口的方式来实现平移不变性。具体地，可以选择一个固定大小的窗口，在图像上滑动窗口，对每个窗口内的图像进行处理。这样，在图像平移时，窗口内的图像内容会随之移动，但窗口的大小和形状保持不变，从而实现了平移不变性。

尺度不变性：为了实现尺度不变性，可以使用图像金字塔（image pyramid）的方法。图像金字塔是一种将原始图像按照不同尺度进行分解的方法。可以通过对原始图像进行降采样或上采样来生成不同尺度的图像。在进行图像处理时，可以在不同尺度的图像上进行操作，从而实现尺度不变性。

旋转不变性：要实现旋转不变性，可以使用特征描述子（feature descriptor）的方法。特征描述子是一种用来描述图像局部特征的方法，它可以提取出图像中的关键特征，并将其表示为一个向量或一个特征描述子。在进行图像处理时，可以使用特征描述子来匹配和比较图像中的特征，从而实现旋转不变性。特征描述子的选择和设计可以考虑使用具有旋转不变性的算法，例如SIFT（尺度不变特征变换）等。

总结起来，要实现平移不变性、尺度不变性和旋转不变性，可以使用滑动窗口、图像金字塔和特征描述子等方法。这些方法可以在不同尺度和旋转角度下对图像进行处理和比较，从而实现对平移、尺度和旋转的不变性。

有两座楼A和B
A楼有3层，1楼正北是大门，1楼正东有一个上下的直梯，但是只能到2楼，2楼到3楼只有正西有个上下的手扶电梯
B楼在A楼的正南方，AB楼之间隔了一条自西向东走向的河叫奈河，河的上游有座桥，下游有个码头，可以坐船来往南北两岸
B楼有正南是大门，但是现在在修理，正西有个侧门，东南方有个直梯，只能在5楼3楼和1楼停，4楼有个楼梯可以来往5楼
现在奈河上的桥正在维修，我在A楼楼顶，怎么到底B楼的4楼？


降噪：语音信号通常会受到环境噪声的影响，如背景噪声、电器噪声等。降噪技术可以通过滤波或估计噪声模型来减少噪声的影响，以提高语音信号的质量和清晰度。

声音增强：有时语音信号的音量可能较低，这可能会影响语音识别系统的性能。声音增强技术可以通过放大语音信号的幅度，使其达到适当的音量范围。

分帧：语音信号是连续的，为了进行后续的特征提取，需要将语音信号分割成短时间窗口。通常，每个窗口的长度为20-30毫秒，窗口之间有一定的重叠。

加窗：分帧后的语音信号可能会引入频谱泄漏，为了减少这种影响，可以对每个时间窗口的语音信号应用窗函数。常用的窗函数有汉明窗、矩形窗等。

预加重：语音信号中的高频部分对于语音识别非常重要，但在传输过程中可能会受到衰减的影响。预加重可以通过对分帧后的语音信号进行高通滤波，强调高频部分，以提高特征的区分度。

频谱计算：对每个窗口的语音信号进行傅里叶变换，将时域信号转换为频域信号。傅里叶变换可以得到语音信号的频谱信息，用于后续的特征提取。

特征提取：从频谱中提取出一些有用的特征，以描述语音信号的特性。常用的特征提取方法包括梅尔频率倒谱系数（MFCC）和滤波器组频率倒谱系数（FBANK）。这些特征可以捕捉语音信号的频谱形状和能量分布等信息。


https://blog.csdn.net/weixin_43198122/article/details/119377985

语音识别所用的语音数据集文件基本上都是.wav文件，就算原始语音不是wav也会转为wav


记忆是稀有的而非普遍的，不断的输入不同的信号但相同语义但来刺激记忆
记忆除了记忆语义更多的是事物的关系，而且很多时候关系比事物的语义更重要，比如自动驾驶我不用一定要知道我前面的是什么，我只需知道不要撞他就好了
语音也只需记住特定的信号就行了，也就是音素，语言是要学习的，也就是需要去侧重记忆一些音素，而对不侧重记忆的音素，可以当作噪音
