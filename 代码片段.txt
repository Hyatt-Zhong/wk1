===========================================================================================
FILE* fd_record=0;
int record_over=0;
int frm_count=0;

static int DoWriteFrame1(time_t tm, int frm_type, BYTE *buf, int buf_size)
{
	int ret;
    int blkSize = 0;
    char *blkData = NULL;
    tcblk_slots *frmBlk;
    int offset = 0;  

	FILE_HEAD   file_head = {FRM_FLAG, FILEVER_HEAD, 0x00000100, 0};

	
	
	//pHandler->m_fdData = fopen(recName, "ab+");
	if (fd_record==0&&record_over==0)
	{
		char str[30]={0};
		time_t timestamp = time(NULL);
    	sprintf(str, "/media/%ld.264", timestamp);
		
		// int recfd = open(str, O_CREAT | O_RDWR | O_APPEND | O_CLOEXEC);
		// if(recfd <= 0){
		// ZRT_LOG_INFO("open %s failed\n", str);
		// return FALSE;
		// }
		fd_record=fopen(str,"ab+");
        fwrite( &file_head, sizeof(FILE_HEAD), 1, fd_record);

		ZRT_LOG_ERR("#SD_RECORD# record %s fd = 0x%x\n",str,fd_record);
	}

	if (fd_record==0)
	{
		return 0;
	}
	
	

	//printf("DoWrite size=%d, type=%d\n", buf_size, frm_type);

	//帧头
	FRAME_INFO  frm_hdr;
    frm_hdr.frm_type = frm_type;
    frm_hdr.buf_size = buf_size;
    frm_hdr.time = tm;
    ret = fwrite(&frm_hdr, sizeof(frm_hdr), 1, fd_record);
	if(ret <= 0){
		ZRT_LOG_ERR("write frame head failed!\n");
		
		return 0;
	}
	if(FRM_TYPE_I == frm_type){	
		frm_count++;
		if (frm_count>20)
		{
			ZRT_LOG_ERR("#SD_RECORD# record over\n");
			record_over=1;
			fclose(fd_record);
			fd_record=0;
			return 0;
		}
		
	}
	
	//帧数据
    frmBlk = (tcblk_slots *)buf;
    offset = 0;    
	while(1)
    {
        blkSize = tcblk_step_get_blk_data(frmBlk, offset, &blkData);
        if((0 == blkSize) || (NULL == blkData)){
            break;
        }

        ret = fwrite(blkData, blkSize, 1, fd_record);
		if(ret != 1){
			ZRT_LOG_ERR("fwrite frame fail, errno = %d\n", errno);
			return 0;
		}
		
		offset += blkSize;
    }

	return buf_size;
}
===========================================================================================


struct record_stu
{
	FILE* fd_record;
	int record_over;
	int frm_count;
};

struct record_stu RS[8]={0};

int write_2_media(int frm_type, unsigned char *buf, int buf_size ,int chn)
{
	int ret;
    int blkSize = 0;
    char *blkData = NULL;
    int offset = 0;  
	int record_over=RS[chn].record_over;

	if (RS[chn].fd_record==0&&record_over==0)
	{
		char str[30]={0};
		time_t timestamp = time(NULL);
    	sprintf(str, "/media/%d_%ld.264", chn, timestamp);
		RS[chn].fd_record=fopen(str,"wb+");
		ZRT_LOG_ERR("#SD_RECORD# write_2_media %s fd = 0x%x\n",str,RS[chn].fd_record);
	}

	if (RS[chn].fd_record==0)
	{
		return 0;
	}
	

	//printf("DoWrite size=%d, type=%d\n", buf_size, frm_type);

	// if(1 == frm_type){	
	// 	RS[chn].frm_count++;
	// 	if (RS[chn].frm_count>20)
	// 	{
	// 		ZRT_LOG_ERR("#SD_RECORD# write_2_media over\n");
	// 		RS[chn].record_over=1;
	// 		fclose(RS[chn].fd_record);
	// 		RS[chn].fd_record==0;
	// 		return 0;
	// 	}
		
	// }
	
	if (RS[chn].fd_record!=0)
    	ret = fwrite(buf, buf_size, 1, RS[chn].fd_record);
    	// ret = fwrite("buf1", 4, 1, RS[chn].fd_record);
	

	return 0;
}
static int GetFrameType(int playloadType, VENC_DATA_TYPE_U mDataType) { 
	int frameType;
	if(1 == playloadType){
		frameType = (H265E_NALU_ISLICE == mDataType.enH265EType) ? 1 : 0;
	}
	else{
		frameType = (H264E_NALU_ISLICE == mDataType.enH264EType) ? 1 : 0;
	}
	return frameType;
}

static void SendData(int chn, int streamType, VENC_STREAM_S *pVencFrame)
{
	if (streamType!=0)
	{
		return;
	}
	
	unsigned int frm_len = pVencFrame->mpPack->mLen0 + pVencFrame->mpPack->mLen1;
	int iFrameType = GetFrameType(camera_allcfg.m_capture.payloadtype, pVencFrame->mpPack->mDataType);

	unsigned char *buf = NULL;
	int offset = 0;
	if (iFrameType)
	{
		VencHeaderData stSpsPpsInfo;
		VENC_CHN mVeChn = chn * 4 + streamType;
		int tmpret = AW_MPI_VENC_GetH264SpsPpsInfo(mVeChn, &stSpsPpsInfo);

		frm_len += stSpsPpsInfo.nLength;
		buf = (unsigned char *)malloc(frm_len);
		memcpy((void *)buf, stSpsPpsInfo.pBuffer, stSpsPpsInfo.nLength);
		offset += stSpsPpsInfo.nLength;
	}
	else
	{
		buf = (unsigned char *)malloc(frm_len);
	}

	if ((NULL != pVencFrame->mpPack->mpAddr0) && (0 != pVencFrame->mpPack->mLen0))
	{
		memcpy(buf + offset, (char *)pVencFrame->mpPack->mpAddr0, pVencFrame->mpPack->mLen0);
		offset += pVencFrame->mpPack->mLen0;
	}
	if ((NULL != pVencFrame->mpPack->mpAddr1) && (0 != pVencFrame->mpPack->mLen1))
	{
		memcpy(buf + offset, (char *)pVencFrame->mpPack->mpAddr1, pVencFrame->mpPack->mLen1);
	}

	int frm_type = GetNALType(camera_allcfg.m_capture.payloadtype, pVencFrame->mpPack->mDataType);
	write_2_media(iFrameType,buf, frm_len, chn);

	free(buf);

}

===========================================================================================

#define SERVER_IP "127.0.0.1"
#define SERVER_PORT 16663
struct message
{
    int cmd;
    char param[256];
};

void handle(char* buf,int len, void* args){
	ZRT_AudioHandler *audio = (ZRT_AudioHandler *)args;
	struct message *pmsg=buf;

	switch (pmsg->cmd)
	{
	case 1:
		pthread_mutex_lock(&audio->mutex);
    	snprintf(audio->sToneFileName, sizeof(audio->sToneFileName), "%s", pmsg->param);
    	pthread_mutex_unlock(&audio->mutex);
		break;
	
	default:
		break;
	}

}

static void* audio_test_thread_func(void* args){

    int server_fd, client_fd;
    struct sockaddr_in server_addr, client_addr;
    fd_set readfds;
    int activity, i, addrlen, errno;
    int BUFFER_SIZE=512;
    char *success="success";
    char buffer[BUFFER_SIZE];

    // 创建套接字
    if ((server_fd = socket(AF_INET, SOCK_STREAM, 0)) == 0) {
        perror("socket failed");
        exit(EXIT_FAILURE);
    }

    // 初始化服务器地址
    server_addr.sin_family = AF_INET;
    server_addr.sin_addr.s_addr = INADDR_ANY;
    server_addr.sin_port = htons(SERVER_PORT);

    // 将套接字绑定到服务器地址
    if (bind(server_fd, (struct sockaddr *)&server_addr, sizeof(server_addr)) < 0) {
        perror("bind failed");
        exit(EXIT_FAILURE);
    }

    // 监听连接
    if (listen(server_fd, 3) < 0) {
        perror("listen");
        exit(EXIT_FAILURE);
    }

    printf("Server started. Waiting for connections...\n");

    while (1) {
        // 清空文件描述符集合
        FD_ZERO(&readfds);

        // 将服务器套接字添加到文件描述符集合
        FD_SET(server_fd, &readfds);

        // 使用 select 函数监听多个套接字
        activity = select(10, &readfds, NULL, NULL, NULL);

        if ((activity < 0)) {
            printf("select error");
        }

        // 如果有新的连接请求
        if (FD_ISSET(server_fd, &readfds)) {
            int addrlen = sizeof(client_addr);
            if ((client_fd = accept(server_fd, (struct sockaddr *)&client_addr, (socklen_t*)&addrlen)) < 0) {
                
            }
            else
            {
                FD_SET(client_fd, &readfds);
                printf("New connection, socket fd is %d, ip is : %s, port : %d\n", client_fd, inet_ntoa(client_addr.sin_addr), ntohs(client_addr.sin_port));
            }
        }

        if (FD_ISSET(client_fd, &readfds)) {
                int valread=0;
                if ((valread = read(client_fd, buffer, BUFFER_SIZE)) == 0) {
                    getpeername(client_fd, (struct sockaddr*)&client_addr, (socklen_t*)&addrlen);
                    printf("Host disconnected, ip %s, port %d\n", inet_ntoa(client_addr.sin_addr), ntohs(client_addr.sin_port));
                    close(client_fd);
                } else {
                    handle(buffer,valread,args);
                    send(client_fd, success, strlen(success), 0);
                }
            }

    }
}


	// if((iRet = pthread_create(&initTid, NULL, ZRT_Audio_Delay_Init_Task, (void *)handler)))
	// {
	// 	ZRT_LOG_ERR("init Thread create fail, iRet=[%d]\n", iRet);
	// 	goto err_audio_in_init;
	// }
	// pthread_detach(initTid);

	pthread_t atestid;
	pthread_create(&atestid, NULL, audio_test_thread_func, (void *)handler);
	pthread_detach(atestid);


============================================================================================
static int GetFrameType(int playloadType, VENC_DATA_TYPE_U mDataType) { 
	int frameType;
	if(1 == playloadType){
		frameType = (H265E_NALU_ISLICE == mDataType.enH265EType) ? 1 : 0;
	}
	else{
		frameType = (H264E_NALU_ISLICE == mDataType.enH264EType) ? 1 : 0;
	}
	return frameType;
}


int Record()
{
	static time_t beg = 0;
	if (beg < 1702879726)
	{
		beg = time(NULL);
		if (beg < 1702879726)
		{
			return 0;
		}
		
		ZRT_LOG_INFO("beg %ld\n",beg);
	}

	time_t now = time(NULL);
	bool ret = !(now - beg > 40);
	static int i=0;
	if (!ret&& i==0)
	{
		i++;
		ZRT_LOG_INFO("end %ld\n",now);
	}
	
	return (int)ret;
}

static void VWrite(FILE *fp, char *buf, int len, unsigned long long time, char isIFrame)
{
	if (fp)
	{
		// ZRT_LOG_INFO("write v frm\n");
		fwrite("video_frame", 11, 1, fp);
		fwrite(&time, 8, 1, fp);
		fwrite(&isIFrame,1,1,fp);
		fwrite(buf, len, 1, fp);
	}
	// if (!fp)
	// {
	// 	return ;
	// }
	

	// static FILE* xfp=0;
	// if (xfp == 0)
	// {
	// 	xfp=fopen("/media/264.264","wb+");
	// 	ZRT_LOG_INFO("open 264.264\n");
	// }
	
	// if (xfp)
	// {
	// 	fwrite(buf, len, 1, xfp);
	// }
	
	return 0;
}

static void WriteVideo(int chn, int streamType, VENC_STREAM_S *pVencFrame)
{
	if (streamType != 0)
	{
		return;
	}

	static FILE *fp = 0;
	char *filename = "/media/VFrames.file";

	int isKey = GetFrameType(camera_allcfg.m_capture.payloadtype, pVencFrame->mpPack->mDataType);
	if (!Record())
	{
		if (fp)
		{
			fclose(fp);
			fp = 0;
			ZRT_LOG_INFO("close file %s\n", filename);
		}
		return;
	}
	else
	{
		if (!fp&&isKey)
		{
			fp = fopen(filename, "wb+");
			ZRT_LOG_INFO("open file %s\n", filename);
		}
	}
	// ZRT_LOG_INFO("here ..\n");

	unsigned int frm_len = pVencFrame->mpPack->mLen0 + pVencFrame->mpPack->mLen1;
	int iFrameType = GetFrameType(camera_allcfg.m_capture.payloadtype, pVencFrame->mpPack->mDataType);
	
	// ZRT_LOG_INFO("here ..\n");

	unsigned char *buf = NULL;	
	int offset = 0;
	if (iFrameType)
	{
		VencHeaderData stSpsPpsInfo;
		VENC_CHN mVeChn = chn * 4 + streamType;
		int tmpret = AW_MPI_VENC_GetH264SpsPpsInfo(mVeChn, &stSpsPpsInfo);

		frm_len += stSpsPpsInfo.nLength;
		buf = (unsigned char *)malloc(frm_len);
		memcpy((void *)buf, stSpsPpsInfo.pBuffer, stSpsPpsInfo.nLength);
		offset += stSpsPpsInfo.nLength;
		ZRT_LOG_INFO("get spspps info %d\n",stSpsPpsInfo.nLength);
	}
	else
	{
		buf = (unsigned char *)malloc(frm_len);
	}

	// ZRT_LOG_INFO("malloc %d\n", frm_len);
	

	if ((NULL != pVencFrame->mpPack->mpAddr0) && (0 != pVencFrame->mpPack->mLen0))
	{
		memcpy(buf + offset, (char *)pVencFrame->mpPack->mpAddr0, pVencFrame->mpPack->mLen0);
		offset += pVencFrame->mpPack->mLen0;
	}
	if ((NULL != pVencFrame->mpPack->mpAddr1) && (0 != pVencFrame->mpPack->mLen1))
	{
		memcpy(buf + offset, (char *)pVencFrame->mpPack->mpAddr1, pVencFrame->mpPack->mLen1);
	}

	// ZRT_LOG_INFO("copy ..\n");

	int frm_type = GetNALType(camera_allcfg.m_capture.payloadtype, pVencFrame->mpPack->mDataType);

	char ch=iFrameType?'\1':'\0';
	VWrite(fp, buf, frm_len, pVencFrame->mpPack->mPTS,ch);

	free(buf);
}

if (chn  == 0&& streamType==0)
{
	WriteVideo(0,0,pVencFrame);
}


static void PWrite(char *buf, int len, unsigned long long time)
{
	if (!Record()) return;
	static FILE* fp = 0;
	if (fp==0)
	{
		fp = fopen("/media/PCM.file","wb+");
	}

	if (fp)
	{
		fwrite("audio_frame", 11, 1, fp);
		fwrite(&time, 8, 1, fp);
		fwrite(buf, len, 1, fp);
	}

	static FILE* xfp = 0;
	if (xfp==0)
	{
		xfp = fopen("/media/raw.pcm","wb+");
	}

	if (xfp)
	{
		fwrite(buf, len, 1, xfp);
	}
}


static void AWrite(FILE *fp, char *buf, int len, unsigned long long time)
{
	if (fp)
	{
		fwrite("audio_frame", 11, 1, fp);
		fwrite(&time, 8, 1, fp);
		fwrite(buf, len, 1, fp);
	}

	static FILE* afp = 0;
	if (afp==0)
	{
		afp = fopen("/media/rec.g711a","wb+");
	}

	if (afp)
	{
		fwrite(buf, len, 1, afp);
	}
	
	
}

static void WriteAudio(char *buf, int len, unsigned long long time)
{
	static FILE *fp = 0;
	char *filename = "/media/AFrames.file";

	if (!Record())
	{
		if (fp)
		{
			fclose(fp);
			fp = 0;
			ZRT_LOG_INFO("close file %s\n", filename);
		}
		return;
	}
	else
	{
		if (!fp)
		{
			fp = fopen(filename, "wb+");
			ZRT_LOG_INFO("open file %s\n", filename);
		}
	}

	AWrite(fp, buf, len, time);
}

PWrite(frm.mpAddr,frm.mLen,frm.mTimeStamp);
WriteAudio(stream.pStream,stream.mLen,stream.mTimeStamp);


1. 展开：torch.flatten()
torch.flatten(input, start_dim=0, end_dim=-1)：将输入张量在指定的维度范围内展平。
示例:

import torch

x = torch.tensor([[1, 2], [3, 4]])
y = torch.flatten(x)
print(y)  # 输出: tensor([1, 2, 3, 4])

2. 升维：torch.unsqueeze()
torch.unsqueeze(input, dim)：在指定位置增加一个维度。
示例:

x = torch.tensor([1, 2, 3, 4])
y = torch.unsqueeze(x, 0)  # 在第0维增加
print(y)  # 输出: tensor([[1, 2, 3, 4]])

3. 降维：torch.squeeze()
torch.squeeze(input, dim=None)：去除输入张量中所有大小为1的维度。如果指定了维度，那么该维度大小必须为1，才可以被去除。
示例:

x = torch.tensor([[[1, 2, 3, 4]]])
y = torch.squeeze(x)  # 去掉大小为1的维度
print(y)  # 输出: tensor([1, 2, 3, 4])

4. 调整张量形状：torch.reshape()
torch.reshape(input, shape)：改变输入张量的形状。
示例:

x = torch.arange(8)  # tensor([0, 1, 2, 3, 4, 5, 6, 7])
y = torch.reshape(x, (2, 4))
print(y)
# 输出:
# tensor([[0, 1, 2, 3],
#         [4, 5, 6, 7]])

5. 转置：torch.transpose()
torch.transpose(input, dim0, dim1)：将输入张量的两个维度进行互换。
示例:

x = torch.tensor([[1, 2], [3, 4]])
y = torch.transpose(x, 0, 1)
print(y)  # 输出: tensor([[1, 3], [2, 4]])

6. 排列维度：torch.permute()
torch.permute(input, dims)：更一般地重新排列张量的维度。
示例:

x = torch.randn(2, 3, 5)
y = x.permute(2, 0, 1)
print(y.shape)  # 输出: torch.Size([5, 2, 3])

######################################################################################
在PyTorch中，你可以根据需要在训练过程中动态地修改模型的结构。这包括在运行时添加额外的层。这种灵活性是PyTorch动态图特性的一个重要优势。

下面是一个示例，展示了如何在训练过程中根据模型当前的损失动态地向模型中添加一个全连接层。在这个例子中，如果某个epoch的损失没有显著下降，则增加一个新的全连接层以尝试改进模型性能。

import torch
from torch import nn, optim
from torch.autograd import Variable

# 数据集
x_data = Variable(torch.Tensor([[1.0], [2.0], [3.0], [4.0], [5.0]]))
y_data = Variable(torch.Tensor([[2.0], [4.0], [6.0], [8.0], [10.0]]))

# 定义模型
class DynamicLinearRegression(nn.Module):
    def __init__(self):
        super(DynamicLinearRegression, self).__init__()
        self.layers = nn.ModuleList([nn.Linear(1, 1)])

    def forward(self, x):
        for layer in self.layers:
            x = layer(x)
        return x

    def add_layer(self):
        # 当前最后一层的输出特征数即为下一层的输入特征数
        input_features = self.layers[-1].out_features
        # 添加一个新的全连接层，输出特征数与输入特征数相同
        new_layer = nn.Linear(input_features, 1)
        self.layers.append(new_layer)

# 实例化模型
model = DynamicLinearRegression()

# 损失函数和优化器
criterion = nn.MSELoss(reduction='sum')
optimizer = optim.SGD(model.parameters(), lr=0.01)

# 训练模型
previous_loss = float('inf')
for epoch in range(500):
    # 前向传播
    y_pred = model(x_data)

    # 计算损失
    loss = criterion(y_pred, y_data)
    print(epoch, loss.item())

    # 检查是否需要添加层
    if loss.item() > previous_loss:
        print("Adding new layer")
        model.add_layer()
        optimizer = optim.SGD(model.parameters(), lr=0.01)  # 重新配置优化器

    previous_loss = loss.item()

    # 反向传播和优化
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

# 测试模型
x_test = Variable(torch.Tensor([[6.0]]))
y_test = model(x_test)
print("预测结果：", y_test.data[0][0].item())

注意事项：
模型复杂度增加：动态添加层将增加模型的复杂性，这可能导致过拟合，特别是当数据集较小或不够复杂时。
优化器重置：每次添加新层时，需要重新配置优化器，因为模型参数已经改变。
性能监控：在实际应用中，监控模型的性能非常重要，以确保添加新层确实带来了性能的提升。
这种动态修改模型结构的方法提供了极大的灵活性，但也需要仔细设计和测试以确保其有效性和效率。

这样的网络模型能否正确存储和加载

在PyTorch中，动态添加层到你的模型并不会阻止你正常地保存和加载整个模型或模型的状态字典（state dict）。但是，你需要确保在加载模型之后，模型具有与保存时相同的结构。这意味着在加载模型之前，你需要重建模型的结构，包括在训练过程中动态添加的所有层。

保存模型
保存模型通常有两种方法：直接保存整个模型（包括其结构和参数），或只保存模型参数（推荐的方式）。

保存整个模型：
torch.save(model, 'model.pth')

保存模型的状态字典：
torch.save(model.state_dict(), 'model_state_dict.pth')

加载模型
加载模型时，如果你保存的是整个模型，可以直接加载；如果保存的是状态字典，需要首先重建模型结构。

加载整个模型：
model = torch.load('model.pth')

加载模型状态字典：
首先，你需要有一个与保存时相同结构的模型对象，然后加载状态字典：

model = DynamicLinearRegression()
# 重建模型结构，确保与保存前一致
# model.add_layer() 根据需要调用
model.load_state_dict(torch.load('model_state_dict.pth'))

示例：动态重建并加载模型
如果模型在训练过程中动态地改变了，你需要在加载模型前，恢复其结构到与保存时相同的状态。这通常需要你记录下在训练过程中所做的改变，例如添加了多少层。

假设你已经保存了模型的状态字典，并知道在训练过程中添加了几层，可以按以下方式重建并加载模型：

# 假设我们知道添加了3层
model = DynamicLinearRegression()
for _ in range(3):
    model.add_layer()

model.load_state_dict(torch.load('model_state_dict.pth'))

注意：
当使用torch.save来保存整个模型时，实际上是保存了模型的序列化数据，这依赖于Python的pickle模块，因此可能会在不同的Python环境或PyTorch版本间遇到兼容性问题。
推荐使用保存和加载状态字典的方法，因为这种方式更加灵活和稳定，尤其是在涉及到复杂模型结构或跨平台操作时。


普及型天文学书籍:

《宇宙简史》作者：史蒂芬·霍金。这本书以浅显易懂的方式介绍了宇宙的起源、结构以及主要天体，非常适合天文学初学者。
《天文学与宇宙学导论》作者：杰弗里·贝内特等。这本书系统地介绍了天文学的基础知识，包括天体的种类和特性，以及宇宙的大尺度结构。
专业天文学教材:

《现代天文学导论》作者：迈克尔·泽利克。这本教材详细介绍了天文学的各个分支，包括恒星、行星、星系等天体的详细分类和特征。
《银河系与星系的结构和动力学》作者：詹姆斯·宾尼。此书深入探讨了银河系及其他星系的结构和动力学，适合对天文学有一定基础的读者。
天体观测指南:

《观星三百问》作者：汪荣祖。这本书以问答形式介绍了许多关于天文观测的实用信息，包括如何观测银河系中的著名天体。
《星际旅行者的指南》作者：艾伦·哈斯。这本书提供了详细的指南和地图，帮助读者识别和了解夜空中的星座、星系和其他天体。
天体物理学相关书籍:

《天体物理学入门》作者：尼尔·德葛拉斯·泰森。这本书介绍了天体物理学的基本概念，帮助读者理解天体的物理性质和演化过程。